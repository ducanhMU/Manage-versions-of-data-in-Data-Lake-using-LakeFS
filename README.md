# HÆ°á»›ng dáº«n khá»Ÿi Ä‘á»™ng vÃ  tÆ°Æ¡ng tÃ¡c há»‡ thá»‘ng

## 1. Khá»Ÿi Ä‘á»™ng há»‡ thá»‘ng cÆ¡ báº£n

**ThÃ nh pháº§n:**

* **lakeFS** â€“ Lá»›p quáº£n lÃ½ version dá»¯ liá»‡u
* **PostgreSQL** â€“ LÆ°u metadata cho lakeFS
* **MinIO** â€“ Object store tÆ°Æ¡ng thÃ­ch S3

**BÆ°á»›c thá»±c hiá»‡n:**

* Táº¯t tiáº¿n trÃ¬nh PostgreSQL Ä‘ang chiáº¿m cá»•ng `5432` náº¿u cÃ³:

  ```bash
  sudo systemctl stop postgresql
  ```

* Khá»Ÿi cháº¡y há»‡ thá»‘ng báº±ng Docker Compose:

  ```bash
  docker compose up -d
  ```

---

## 2. Káº¿t ná»‘i vÃ  tÆ°Æ¡ng tÃ¡c qua CLI

### 2.1. DÃ¹ng `mc` (MinIO Client)

**Thao tÃ¡c:**

* Truy cáº­p container `mc`:

  ```bash
  docker compose exec -it mc sh
  ```

* ThoÃ¡t:

  ```bash
  exit
  ```

**CÃ i Ä‘áº·t káº¿t ná»‘i tá»›i MinIO:**

```bash
mc alias set myminio http://minio:9000 admin Admin12345
```

**Má»™t sá»‘ lá»‡nh thÆ°á»ng dÃ¹ng:**

* Liá»‡t kÃª cÃ¡c bucket:

  ```bash
  mc ls myminio
  ```

* Táº¡o bucket má»›i:

  ```bash
  mc mb myminio/mybucket
  ```

* Upload dá»¯ liá»‡u tá»« thÆ° má»¥c `/data` trong container `mc` lÃªn MinIO:

  ```bash
  mc cp /data/file.csv myminio/mybucket
  ```

> ğŸ“Œ *LÆ°u Ã½:* ThÆ° má»¥c `/data` Ä‘Ã£ Ä‘Æ°á»£c mount tá»« thÆ° má»¥c `data/` á»Ÿ mÃ¡y host, nÆ¡i báº¡n Ä‘á»ƒ cÃ¡c file cáº§n upload.

---

### 2.2. DÃ¹ng `lakectl` (CLI cá»§a lakeFS)

**Thao tÃ¡c:**

* Truy cáº­p container `lakefs`:

  ```bash
  docker compose exec -it lakefs sh
  ```

* ThoÃ¡t:

  ```bash
  exit
  ```

**Ghi chÃº:**

* Container `lakefs` Ä‘Ã£ cÃ i sáºµn `lakectl`.
* File `lakectl.yaml` Ä‘Ã£ Ä‘Æ°á»£c mount vÃ o `/home/lakefs/.lakectl.yaml`, chá»©a sáºµn `access_key_id`, `secret_access_key` vÃ  `endpoint_url`, nÃªn `lakectl` sáº½ tá»± Ä‘á»™ng káº¿t ná»‘i khi sá»­ dá»¥ng.

---

## 3. TÆ°Æ¡ng tÃ¡c vá»›i há»‡ thá»‘ng lakeFS

### Táº¡o repository má»›i:

```bash
lakectl repo create lakefs://myrepo s3://mybucket
```

### Táº¡o nhÃ¡nh (branch):

```bash
lakectl branch create lakefs://myrepo@dev --source main
```

### Upload dá»¯ liá»‡u:

(Sá»­ dá»¥ng `mc` nhÆ° hÆ°á»›ng dáº«n á»Ÿ má»¥c 2.1)

### Biáº¿n Ä‘á»•i dá»¯ liá»‡u (transform) vÃ  thao tÃ¡c Git-like:

* Kiá»ƒm tra sá»± khÃ¡c biá»‡t:

  ```bash
  lakectl diff lakefs://myrepo@dev
  ```

* Commit:

  ```bash
  lakectl commit lakefs://myrepo@dev -m "My update"
  ```

* Merge vÃ o nhÃ¡nh chÃ­nh:

  ```bash
  lakectl merge lakefs://myrepo@dev --destination lakefs://myrepo@main
  ```

* Rollback náº¿u cáº§n:

  ```bash
  lakectl reset lakefs://myrepo@dev
  ```

* Táº¡o nhÃ¡nh má»›i Ä‘á»ƒ thá»­ nghiá»‡m thÃªm:

  ```bash
  lakectl branch create lakefs://myrepo@experiment --source main
  ```

* CÃ³ thá»ƒ cáº¥u hÃ¬nh hook pre-merge, post-commit,... tÃ¹y nhu cáº§u.

---

## 4. Káº¿t ná»‘i vá»›i Apache Spark

* CÃ i Ä‘áº·t Spark vÃ  cáº¥u hÃ¬nh file `spark-defaults.conf` Ä‘á»ƒ sá»­ dá»¥ng `s3a://` endpoint cá»§a MinIO.

* Äáº£m báº£o thÃªm dependency Hadoop AWS:

```bash
--packages org.apache.hadoop:hadoop-aws:3.3.2
```

* Thiáº¿t láº­p cÃ¡c biáº¿n mÃ´i trÆ°á»ng cáº§n thiáº¿t:

```bash
spark.hadoop.fs.s3a.access.key=admin
spark.hadoop.fs.s3a.secret.key=Admin12345
spark.hadoop.fs.s3a.endpoint=http://minio:9000
spark.hadoop.fs.s3a.path.style.access=true
spark.hadoop.fs.s3a.impl=org.apache.hadoop.fs.s3a.S3AFileSystem
```

---

## 5. Xá»­ lÃ½ dá»¯ liá»‡u vá»›i Spark

* Äá»c dá»¯ liá»‡u tá»« bucket:

```python
spark.read.csv("s3a://mybucket/file.csv", header=True)
```

* Ghi dá»¯ liá»‡u sau xá»­ lÃ½:

```python
df.write.csv("s3a://mybucket/processed/")
```

* CÃ³ thá»ƒ Ã¡p dá»¥ng thÃªm cÃ¡c bÆ°á»›c ETL, xá»­ lÃ½ vá»›i Spark SQL, hoáº·c huáº¥n luyá»‡n mÃ´ hÃ¬nh MLlib táº¡i Ä‘Ã¢y.

---

## 6. Káº¿t ná»‘i vá»›i Delta Lake

* CÃ i Ä‘áº·t Delta Lake:

```bash
--packages io.delta:delta-core_2.12:2.4.0
```

* Thiáº¿t láº­p Spark session vá»›i Delta:

```python
from pyspark.sql import SparkSession
spark = SparkSession.builder \
    .appName("DeltaLake Integration") \
    .config("spark.sql.extensions", "io.delta.sql.DeltaSparkSessionExtension") \
    .config("spark.sql.catalog.spark_catalog", "org.apache.spark.sql.delta.catalog.DeltaCatalog") \
    .getOrCreate()
```

---

## 7. Thao tÃ¡c vá»›i Delta Lake

* Ghi dá»¯ liá»‡u dÆ°á»›i dáº¡ng Delta Table:

```python
df.write.format("delta").save("s3a://mybucket/delta-table")
```

* Äá»c dá»¯ liá»‡u Delta:

```python
delta_df = spark.read.format("delta").load("s3a://mybucket/delta-table")
```

* Time travel:

```python
spark.read.format("delta").option("versionAsOf", 0).load("s3a://mybucket/delta-table")
```

* Merge, update, delete vá»›i Delta Lake API nÃ¢ng cao.

---

## Cáº¥u trÃºc thÆ° má»¥c dá»± Ã¡n

```text
demo/
â”œâ”€â”€ data/             # ThÆ° má»¥c chá»©a dá»¯ liá»‡u upload
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ .env              # Chá»©a cÃ¡c biáº¿n mÃ´i trÆ°á»ng nhÆ° credentials
â”œâ”€â”€ lakectl.yaml      # File cáº¥u hÃ¬nh cho lakectl
â””â”€â”€ README.md         # (file nÃ y)
```

