
services:
  # 1) MinIO (Object Store)
  minio:
    image: minio/minio:latest
    container_name: minio
    ports:
      - "9000:9000"
      - "9001:9001"
    env_file: .env
    volumes:
      - minio-data:/data
      - minio-config:/root/.minio
    command: server /data --console-address ":9001"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      retries: 3

  # 2) PostgreSQL (Metadata Store)
  postgres:
    image: postgres:14-alpine
    container_name: postgres
    ports:
      - "5432:5432"
    env_file: .env
    volumes:
      - postgres-data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER}"]
      interval: 10s
      retries: 5

  # 3) lakeFS Server
  lakefs:
    image: treeverse/lakefs:latest
    container_name: lakefs
    depends_on:
      minio:
        condition: service_healthy
      postgres:
        condition: service_healthy
    ports:
      - "8000:8000" # lakefs api
    env_file: .env
    environment:
      - LAKEFS_DATABASE_TYPE=postgres
      - LAKEFS_DATABASE_POSTGRES_CONNECTION_STRING=postgres://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB}?sslmode=disable
      - LAKEFS_AUTH_ENCRYPT_SECRET_KEY=${LAKEFS_ENCRYPT_SECRET_KEY}
      - LAKEFS_BLOCKSTORE_TYPE=s3
      - LAKEFS_BLOCKSTORE_S3_FORCE_PATH_STYLE=true
      - LAKEFS_BLOCKSTORE_S3_ENDPOINT=http://minio:9000
      - LAKEFS_BLOCKSTORE_S3_DISCOVER_BUCKET_REGION=false
      - LAKEFS_BLOCKSTORE_S3_CREDENTIALS_ACCESS_KEY_ID=${MINIO_ROOT_USER}
      - LAKEFS_BLOCKSTORE_S3_CREDENTIALS_SECRET_ACCESS_KEY=${MINIO_ROOT_PASSWORD}
    volumes:
      - ./lakectl.yaml:/home/lakefs/.lakectl.yaml:ro
      - lakefs-data:/data         # dữ liệu nội bộ lakeFS
      - ./data:/upload            # upload từ máy host vào lakeFS
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:8000/v1/health"]
      interval: 15s
      retries: 5

  # 4) MinIO client (mc) – để upload file dễ dàng
  mc:
    image: minio/mc:latest
    container_name: mc
    entrypoint: ["tail", "-f", "/dev/null"]
    environment:
      - MC_HOST_minio=http://admin:${MINIO_ROOT_PASSWORD}@minio:9000
    volumes:
      - ./data:/data              # cho phép truy cập file upload

  #spark master
  spark-master:
    image: bitnami/spark:3
    container_name: spark-master
    hostname: spark-master
    depends_on:
      - lakefs
    env_file: .env                      # ← load .env
    ports:
      - "7077:7077"
      - "8080:8080"
    environment:
      - SPARK_MODE=master
      - SPARK_MASTER_HOST=spark-master       # broadcast cho client thấy
      - SPARK_MASTER_PORT=7077
      - SPARK_RPC_AUTHENTICATION_ENABLED=yes
      - SPARK_RPC_AUTHENTICATION_SECRET=my-secret
      # Hadoop S3A (data plane)
      - fs.s3a.endpoint=http://minio:9000
      - fs.s3a.path.style.access=true
      - fs.s3a.access.key=${MINIO_ROOT_USER}
      - fs.s3a.secret.key=${MINIO_ROOT_PASSWORD}
      - fs.s3a.connection.ssl.enabled=false
      # lakeFS FileSystem (metadata plane)
      - fs.lakefs.impl=io.lakefs.LakeFSFileSystem
      - fs.lakefs.endpoint=http://lakefs:8000/api/v1
      - fs.lakefs.access.key=${LAKEFS_ACCESS_KEY}
      - fs.lakefs.secret.key=${LAKEFS_SECRET_KEY}
    volumes:
      - ./jobs:/opt/bitnami/spark/jobs:ro
      - ./jars/io-lakefs-hadoop-lakefs-assembly-0.2.5.jar:/opt/bitnami/spark/jars/io-lakefs-hadoop-lakefs-assembly-0.2.5.jar:ro  

   # spark worker
  spark-worker:
    image: bitnami/spark:3
    container_name: spark-worker
    hostname: spark-worker
    depends_on:
      - spark-master
    env_file: .env
    ports:
      - "8081:8081"
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_CORES=1
      - SPARK_WORKER_MEMORY=1g
      - SPARK_WORKER_HOSTNAME=spark-worker
      # Thêm các dòng sau cho xác thực RPC
      - SPARK_RPC_AUTHENTICATION_ENABLED=yes
      - SPARK_RPC_AUTHENTICATION_SECRET=my-secret
      # Hadoop S3A (data plane)
      - fs.s3a.endpoint=http://minio:9000
      - fs.s3a.path.style.access=true
      - fs.s3a.access.key=${MINIO_ROOT_USER}
      - fs.s3a.secret.key=${MINIO_ROOT_PASSWORD}
      - fs.s3a.connection.ssl.enabled=false
      # lakeFS FileSystem (metadata plane)
      - fs.lakefs.impl=io.lakefs.LakeFSFileSystem
      - fs.lakefs.endpoint=http://lakefs:8000/api/v1
      - fs.lakefs.access.key=${LAKEFS_ACCESS_KEY}
      - fs.lakefs.secret.key=${LAKEFS_SECRET_KEY}
    volumes:
      - ./jobs:/opt/bitnami/spark/jobs:ro
      - ./jars/io-lakefs-hadoop-lakefs-assembly-0.2.5.jar:/opt/bitnami/spark/jars/io-lakefs-hadoop-lakefs-assembly-0.2.5.jar:ro
  # spark-worker:
  #   image: bitnami/spark:3
  #   container_name: spark-worker
  #   hostname: spark-worker
  #   depends_on:
  #     - spark-master
  #   env_file: .env                      # ← load .env
  #   ports:
  #     - "8081:8081"
  #   environment:
  #     - SPARK_MODE=worker
  #     - SPARK_MASTER_URL=spark://spark-master:7077
  #     - SPARK_WORKER_CORES=1
  #     - SPARK_WORKER_MEMORY=1g
  #     - SPARK_WORKER_HOSTNAME=spark-worker     # ← thêm
  #     # Hadoop S3A (data plane)
  #     - fs.s3a.endpoint=http://lakefs:8000
  #     - fs.s3a.path.style.access=true
  #     - fs.s3a.access.key=${MINIO_ROOT_USER}
  #     - fs.s3a.secret.key=${MINIO_ROOT_PASSWORD}
  #     # lakeFS FileSystem (metadata plane)
  #     - fs.lakefs.impl=io.lakefs.LakeFSFileSystem
  #     - fs.lakefs.endpoint=http://lakefs:8000/api/v1
  #     - fs.lakefs.access.key=${LAKEFS_ACCESS_KEY}
  #     - fs.lakefs.secret.key=${LAKEFS_SECRET_KEY}
  #   volumes:
  #     - ./jobs:/opt/bitnami/spark/jobs:ro
  #     - ./jars/io-lakefs-hadoop-lakefs-assembly-0.2.5.jar:/opt/bitnami/spark/jars/io-lakefs-hadoop-lakefs-assembly-0.2.5.jar:ro

volumes:
  minio-data:
  minio-config:
  postgres-data:
  lakefs-data:
